apiVersion: v1
kind: Secret
metadata:
  name: llm-backend
type: Opaque
data:
  OPENAI_API_KEY: {openai_key}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-backend
  labels:
    app: llm-backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-backend
  template:
    metadata:
      labels:
        app: llm-backend
    spec:
      volumes:
        - name: llama-volume
          persistentVolumeClaim:
            claimName: llama-pvc
      containers:
        - name: llm-backend
          image: "llm-example/llm-backend:latest"
          resources:
            requests:
              memory: "4Gi"
          ports:
            - containerPort: 5000
          volumeMounts:
            - name: llama-volume
              mountPath: /etc/models/llama
          env:
            - name: LOG_LEVEL
              value: DEBUG
            - name: CHAT_CONTROLLER
              value: {chat_controller}
            - name: LLAMA_MODEL_FILE
              value: /etc/models/llama/{llama_model_file}
            - name: LLAMA_CONTEXT_SIZE
              value: "2048"
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: llm-backend
                  key: OPENAI_API_KEY
---
kind: Service
apiVersion: v1
metadata:
  name: llm-backend
  labels:
    app: llm-backend
spec:
  ports:
    - name: http
      protocol: TCP
      port: 8080
      targetPort: 5000
  selector:
    app: llm-backend
  type: ClusterIP
